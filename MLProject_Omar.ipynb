{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#index1\n",
      "25494917\n",
      "ndex1\n",
      "\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n",
      "13000000\n",
      "13100000\n",
      "13200000\n",
      "13300000\n",
      "13400000\n",
      "13500000\n",
      "13600000\n",
      "13700000\n",
      "13800000\n",
      "13900000\n",
      "14000000\n",
      "14100000\n",
      "14200000\n",
      "14300000\n",
      "14400000\n",
      "14500000\n",
      "14600000\n",
      "14700000\n",
      "14800000\n",
      "14900000\n",
      "15000000\n",
      "15100000\n",
      "15200000\n",
      "15300000\n",
      "15400000\n",
      "15500000\n",
      "15600000\n",
      "15700000\n",
      "15800000\n",
      "15900000\n",
      "16000000\n",
      "16100000\n",
      "16200000\n",
      "16300000\n",
      "16400000\n",
      "16500000\n",
      "16600000\n",
      "16700000\n",
      "16800000\n",
      "16900000\n",
      "17000000\n",
      "17100000\n",
      "17200000\n",
      "17300000\n",
      "17400000\n",
      "17500000\n",
      "17600000\n",
      "17700000\n",
      "17800000\n",
      "17900000\n",
      "18000000\n",
      "18100000\n",
      "18200000\n",
      "18300000\n",
      "18400000\n",
      "18500000\n",
      "18600000\n",
      "18700000\n",
      "18800000\n",
      "18900000\n",
      "19000000\n",
      "19100000\n",
      "19200000\n",
      "19300000\n",
      "19400000\n",
      "19500000\n",
      "19600000\n",
      "19700000\n",
      "19800000\n",
      "19900000\n",
      "20000000\n",
      "20100000\n",
      "20200000\n",
      "20300000\n",
      "20400000\n",
      "20500000\n",
      "20600000\n",
      "20700000\n",
      "20800000\n",
      "20900000\n",
      "21000000\n",
      "21100000\n",
      "21200000\n",
      "21300000\n",
      "21400000\n",
      "21500000\n",
      "21600000\n",
      "21700000\n",
      "21800000\n",
      "21900000\n",
      "22000000\n",
      "22100000\n",
      "22200000\n",
      "22300000\n",
      "22400000\n",
      "22500000\n",
      "22600000\n",
      "22700000\n",
      "22800000\n",
      "22900000\n",
      "23000000\n",
      "23100000\n",
      "23200000\n",
      "23300000\n",
      "23400000\n",
      "23500000\n",
      "23600000\n",
      "23700000\n",
      "23800000\n",
      "23900000\n",
      "24000000\n",
      "24100000\n",
      "24200000\n",
      "24300000\n",
      "24400000\n",
      "24500000\n",
      "24600000\n",
      "24700000\n",
      "24800000\n",
      "24900000\n",
      "25000000\n",
      "25100000\n",
      "25200000\n",
      "25300000\n",
      "25400000\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>abstract</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finding an Initial Basic Feasible Solution for...</td>\n",
       "      <td>Mehdi Toloo, Atefeh Masoumzadeh, Mona Barat</td>\n",
       "      <td>2015</td>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>Nowadays, algorithms and computer programs, wh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tag line generating system using knowledge ext...</td>\n",
       "      <td>Hiroaki Yamane, Masafumi Hagiwara</td>\n",
       "      <td>2015</td>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>This paper proposes a tag line generating syst...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2015</td>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A social contract for virtual institutions</td>\n",
       "      <td>Daniel Memmi</td>\n",
       "      <td>2015</td>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>Computer-mediated social groups, often known a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2015</td>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Solving Dynamic Programming Problems on a Comp...</td>\n",
       "      <td>Yongyang Cai, Kenneth L. Judd, Greg Thain, Ste...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>We implement a dynamic programming algorithm o...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESIS2: Information Value Estimator for Credit ...</td>\n",
       "      <td>Martin Å˜ezÃ¡Ä</td>\n",
       "      <td>2015</td>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>Information value is widely used to assess dis...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Social media analytics: a survey of techniques...</td>\n",
       "      <td>Bogdan Batrinca, Philip C. Treleaven</td>\n",
       "      <td>2015</td>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>This paper is written for (social science) res...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carbon Price Analysis Using Empirical Mode Dec...</td>\n",
       "      <td>Bangzhu Zhu, Ping Wang, Julien Chevallier, Yim...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Computational Economics</td>\n",
       "      <td>Mastering the underlying characteristics of ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crime detection and criminal identification in...</td>\n",
       "      <td>Devendra Kumar Tayal, Arti Jain, Surbhi Arora,...</td>\n",
       "      <td>2015</td>\n",
       "      <td>AI &amp; Society</td>\n",
       "      <td>In the current paper, we propose an approach f...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Finding an Initial Basic Feasible Solution for...   \n",
       "1  Tag line generating system using knowledge ext...   \n",
       "2                            Computational Economics   \n",
       "3         A social contract for virtual institutions   \n",
       "4                                       AI & Society   \n",
       "5  Solving Dynamic Programming Problems on a Comp...   \n",
       "6  ESIS2: Information Value Estimator for Credit ...   \n",
       "7  Social media analytics: a survey of techniques...   \n",
       "8  Carbon Price Analysis Using Empirical Mode Dec...   \n",
       "9  Crime detection and criminal identification in...   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0        Mehdi Toloo, Atefeh Masoumzadeh, Mona Barat  2015   \n",
       "1                  Hiroaki Yamane, Masafumi Hagiwara  2015   \n",
       "2                                               NULL  2015   \n",
       "3                                       Daniel Memmi  2015   \n",
       "4                                               NULL  2015   \n",
       "5  Yongyang Cai, Kenneth L. Judd, Greg Thain, Ste...  2015   \n",
       "6                                     Martin Å˜ezÃ¡Ä  2015   \n",
       "7               Bogdan Batrinca, Philip C. Treleaven  2015   \n",
       "8  Bangzhu Zhu, Ping Wang, Julien Chevallier, Yim...  2015   \n",
       "9  Devendra Kumar Tayal, Arti Jain, Surbhi Arora,...  2015   \n",
       "\n",
       "                     venue                                           abstract  \\\n",
       "0  Computational Economics  Nowadays, algorithms and computer programs, wh...   \n",
       "1             AI & Society  This paper proposes a tag line generating syst...   \n",
       "2  Computational Economics                                               NULL   \n",
       "3             AI & Society  Computer-mediated social groups, often known a...   \n",
       "4             AI & Society                                               NULL   \n",
       "5  Computational Economics  We implement a dynamic programming algorithm o...   \n",
       "6  Computational Economics  Information value is widely used to assess dis...   \n",
       "7             AI & Society  This paper is written for (social science) res...   \n",
       "8  Computational Economics  Mastering the underlying characteristics of ca...   \n",
       "9             AI & Society  In the current paper, we propose an approach f...   \n",
       "\n",
       "   citations  \n",
       "0          3  \n",
       "1          2  \n",
       "2          0  \n",
       "3          6  \n",
       "4          0  \n",
       "5          8  \n",
       "6          5  \n",
       "7          9  \n",
       "8          4  \n",
       "9          9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal: figure out what topics received the most citations in a given year\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the data\n",
    "#data_str = open('acm1st10000.txt').read()     # small data\n",
    "#data_str = open('acm.txt',errors=\"ignore\").read()  # BIG DATA  shreyas\n",
    "data_str = open('data/acm.v9/acm.txt',errors=\"ignore\").read()  # BIG DATA  omar\n",
    "\n",
    "data_list = data_str.splitlines()\n",
    "\n",
    "print(data_list[3])\n",
    "print(len(data_list))\n",
    "print(data_list[3][2:])\n",
    "print()\n",
    "\n",
    "# Create the dataframe\n",
    "    # title: (string -- should be bag of words vector)\n",
    "    # authors: (list)\n",
    "    # year: publishing year (int)\n",
    "    # venue: journal the paper was published in (string)\n",
    "    # ind: numeric label/index of this paper (int)\n",
    "    # ref_indces: identification index of the papers that referenced this paper (string)\n",
    "    # abstract: (string -- should be bag of words vector ?)\n",
    "names = ['title', 'authors', 'year', 'venue', 'abstract','citations']\n",
    "\n",
    "\n",
    "#note that we are ignoring ref\n",
    "empty_row = pd.DataFrame(columns=names)\n",
    "df = pd.DataFrame(columns=names)\n",
    "\n",
    "title = \"NULL\"\n",
    "authors = \"NULL\"\n",
    "year = \"NULL\"\n",
    "venue = \"NULL\"\n",
    "index = 0\n",
    "abstract = \"NULL\"\n",
    "citations = 0\n",
    "\n",
    "\n",
    "not1986 = 0\n",
    "\n",
    "dflist = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    if(i%10**6 == 0):\n",
    "        print(i)\n",
    "    prefix = data_list[i][0:2]\n",
    "    if prefix == \"#*\": \n",
    "        title = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#@\":\n",
    "        authors = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#t\":\n",
    "        year = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#c\":\n",
    "        venue = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#!\":\n",
    "        abstract = data_list[i][2:]\n",
    "    if prefix == \"#%\":\n",
    "        citations += 1\n",
    "    if data_list[i] == \"\": #check for the empty string (new article)       \n",
    "        if year == \"2015\":\n",
    "            # print(index,citations) #debug\n",
    "            dflist.append([title, authors, year, venue, abstract,citations])\n",
    "#             df = df.append(empty_row)\n",
    "\n",
    "#             df.at[index,'title'] = title\n",
    "#             df.at[index,'authors'] = authors\n",
    "#             df.at[index,'year'] = year\n",
    "#             df.at[index,'venue'] = venue\n",
    "#             df.at[index,'abstract'] = abstract\n",
    "            title = \"NULL\"\n",
    "            authors = \"NULL\"\n",
    "            year = \"NULL\"\n",
    "            venue = \"NULL\"\n",
    "            abstract = \"NULL\"\n",
    "            \n",
    "            index += 1\n",
    "        citations = 0\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "df = pd.DataFrame.from_records(dflist, columns=names)\n",
    "df.head(10)\n",
    "\n",
    "    \n",
    "# T0-DO:\n",
    "# -----------------------------------------------------------\n",
    "# Force strings in dataframe that we want as ints to be ints\n",
    "# Convert the strings in dataframe to bag of words vectors \n",
    "# Make a dataframe of just 2015 papers\n",
    "\n",
    "# Account for no citations in a dataframe (if citation column is NaN, make it 0)\n",
    "# Account for no abstract (if abstract column is NaN, remove the row completely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df.head(5))\n",
    "#print(newdf)\n",
    "list_2k15_X=df['title'].tolist()\n",
    "list_2k15_y=df['citations'].tolist()\n",
    "#print(list_2k15_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Omar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26921\n",
      "['acm', 'adaptive', 'algorithm', 'analysis', 'application', 'applications', 'approach', 'computer', 'computing', 'conference', 'control', 'data', 'design', 'detection', 'dynamic', 'editorial', 'efficient', 'energy', 'framework', 'fuzzy', 'high', 'human', 'image', 'information', 'international', 'journal', 'learning', 'management', 'method', 'mobile', 'model', 'modeling', 'models', 'multi', 'network', 'networks', 'new', 'online', 'optimization', 'performance', 'problem', 'problems', 'proceedings', 'security', 'sensor', 'social', 'software', 'time', 'web', 'wireless']\n",
      "(26921, 50)\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ntot = len(list_2k15_X)\n",
    "print(n)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "set_to_add=set(['using','based','system','systems','study'])\n",
    "stop_words_NLTK = set(stopwords.words('english'))\n",
    "total_stopwords=stop_words_NLTK|set_to_add\n",
    "BOWvectorizer = CountVectorizer(stop_words=total_stopwords, min_df=0.01, max_df=0.99, max_features=50)\n",
    "X_bow = BOWvectorizer.fit_transform(list_2k15_X).toarray()\n",
    "y = list_2k15_y\n",
    "print(BOWvectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "ntr = ntot // 2\n",
    "nts = ntot - ntr\n",
    "\n",
    "Xtr = X_bow[:ntr,:]\n",
    "ytr = y[:ntr]\n",
    "Xts = X_bow[ntr:,:]\n",
    "yts = y[ntr:]\n",
    "\n",
    "\n",
    "print(X_bow.shape)\n",
    "print(X_bow[0])\n",
    "\n",
    "import sklearn.linear_model\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Create linear regression object\n",
    "regr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "regr.fit(Xtr,ytr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.6698114258410532\n",
      "1 1.9207410780015974\n",
      "1 2.3054462281285124\n",
      "0 1.6698114258410532\n",
      "1 2.0953190893442644\n",
      "1 1.6698114258410532\n",
      "1 2.186472754628486\n",
      "1 1.6698114258410532\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "1 3.1016086118174817\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "1 1.5998307766468667\n",
      "0 1.326687710507461\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "1 1.2849147958132576\n",
      "0 0.1981898816721377\n",
      "1 2.5325230560040968\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "1 1.6320914555240336\n",
      "0 0.1981898816721377\n",
      "0 2.0953190893442644\n",
      "0 0.1981898816721377\n",
      "0 0.1981898816721377\n",
      "1 1.6698114258410532\n",
      "1 1.7803666683580002\n",
      "1 1.6698114258410532\n",
      "3 1.6698114258410532\n",
      "1 1.5811436421757756\n",
      "2 1.8711223549784126\n",
      "2 1.6698114258410532\n",
      "1 1.1304619830027804\n",
      "2 1.6698114258410532\n",
      "3 1.6698114258410532\n",
      "1 1.8711223549784126\n",
      "1 1.6698114258410532\n",
      "1 0.9679481567689988\n",
      "11 1.6698114258410532\n",
      "0 1.6698114258410532\n",
      "10 2.2215579877016287\n",
      "5 1.6698114258410532\n",
      "7 1.5998307766468667\n",
      "2 1.6698114258410532\n",
      "1 1.6698114258410532\n",
      "1 1.6698114258410532\n",
      "11 1.6698114258410532\n",
      "17 3.1749842751358877\n",
      "5 1.6698114258410532\n",
      "8 1.6698114258410532\n",
      "0 1.6698114258410532\n",
      "6 2.9805801904353637\n",
      "3 1.4343883300186673\n",
      "1 1.9661728787850392\n",
      "3 1.6698114258410532\n",
      "2 1.6698114258410532\n",
      "1 0.9684185360190972\n",
      "4 2.784616821247441\n",
      "1 2.2328702593868655\n",
      "9 1.6698114258410532\n",
      "9 1.6698114258410532\n",
      "2 1.6698114258410532\n",
      "19 1.9681385678616123\n",
      "7 2.755079228716676\n",
      "0 0.931255583269205\n",
      "7 2.021444333066432\n",
      "5 1.6698114258410532\n",
      "0 1.6698114258410532\n",
      "1 1.8101858354846505\n",
      "5 2.2328702593868655\n",
      "1 1.6698114258410532\n",
      "3 1.6698114258410532\n",
      "1 1.6698114258410532\n",
      "2 2.9571820613405233\n",
      "8 1.7803666683580002\n",
      "10 2.0953190893442644\n",
      "3 1.6698114258410532\n",
      "0 0.07080238309646147\n",
      "22 1.5114958744267915\n",
      "1 1.1795380466362986\n",
      "2 1.6698114258410532\n",
      "5 1.6698114258410532\n",
      "1 2.784616821247441\n",
      "3 1.6698114258410532\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "yts_hat = regr.predict(Xts)\n",
    "\n",
    "for i in range(100):\n",
    "    print(yts[i],yts_hat[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFIDFVectorizer=TfidfVectorizer(stop_words=stop_words_NLTK, min_df=0.01, max_df=0.9, max_features=30)\n",
    "X = TFIDFVectorizer.fit_transform(list_2k15_X)\n",
    "print(TFIDFVectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
