{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#index1\n",
      "25494917\n",
      "ndex1\n",
      "\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n",
      "13000000\n",
      "13100000\n",
      "13200000\n",
      "13300000\n",
      "13400000\n",
      "13500000\n",
      "13600000\n",
      "13700000\n",
      "13800000\n",
      "13900000\n",
      "14000000\n",
      "14100000\n",
      "14200000\n",
      "14300000\n",
      "14400000\n",
      "14500000\n",
      "14600000\n",
      "14700000\n",
      "14800000\n",
      "14900000\n",
      "15000000\n",
      "15100000\n",
      "15200000\n",
      "15300000\n",
      "15400000\n",
      "15500000\n",
      "15600000\n",
      "15700000\n",
      "15800000\n",
      "15900000\n",
      "16000000\n",
      "16100000\n",
      "16200000\n",
      "16300000\n",
      "16400000\n",
      "16500000\n",
      "16600000\n",
      "16700000\n",
      "16800000\n",
      "16900000\n",
      "17000000\n",
      "17100000\n",
      "17200000\n",
      "17300000\n",
      "17400000\n",
      "17500000\n",
      "17600000\n",
      "17700000\n",
      "17800000\n",
      "17900000\n",
      "18000000\n",
      "18100000\n",
      "18200000\n",
      "18300000\n",
      "18400000\n",
      "18500000\n",
      "18600000\n",
      "18700000\n",
      "18800000\n",
      "18900000\n",
      "19000000\n",
      "19100000\n",
      "19200000\n",
      "19300000\n",
      "19400000\n",
      "19500000\n",
      "19600000\n",
      "19700000\n",
      "19800000\n",
      "19900000\n",
      "20000000\n",
      "20100000\n",
      "20200000\n",
      "20300000\n",
      "20400000\n",
      "20500000\n",
      "20600000\n",
      "20700000\n",
      "20800000\n",
      "20900000\n",
      "21000000\n",
      "21100000\n",
      "21200000\n",
      "21300000\n",
      "21400000\n",
      "21500000\n",
      "21600000\n",
      "21700000\n",
      "21800000\n",
      "21900000\n",
      "22000000\n",
      "22100000\n",
      "22200000\n",
      "22300000\n",
      "22400000\n",
      "22500000\n",
      "22600000\n",
      "22700000\n",
      "22800000\n",
      "22900000\n",
      "23000000\n",
      "23100000\n",
      "23200000\n",
      "23300000\n",
      "23400000\n",
      "23500000\n",
      "23600000\n",
      "23700000\n",
      "23800000\n",
      "23900000\n",
      "24000000\n",
      "24100000\n",
      "24200000\n",
      "24300000\n",
      "24400000\n",
      "24500000\n",
      "24600000\n",
      "24700000\n",
      "24800000\n",
      "24900000\n",
      "25000000\n",
      "25100000\n",
      "25200000\n",
      "25300000\n",
      "25400000\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>abstract</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drupal For Designers by Dani Nordin</td>\n",
       "      <td>Vasile G. Teodorovici</td>\n",
       "      <td>2013</td>\n",
       "      <td>ACM SIGSOFT Software Engineering Notes</td>\n",
       "      <td>A semaphore is a non-negative integer variable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The arithmetical complexity of dimension and r...</td>\n",
       "      <td>Walid A. Najjar, Raj Yavatkar, Scott Rixner</td>\n",
       "      <td>2013</td>\n",
       "      <td>ACM Transactions on Computational Logic (TOCL)</td>\n",
       "      <td>Constructive dimension and constructive strong...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low-complexity coding and source-optimized clu...</td>\n",
       "      <td>S. Tucker Taft, Jeff Boleng</td>\n",
       "      <td>2013</td>\n",
       "      <td>ACM Transactions on Sensor Networks (TOSN)</td>\n",
       "      <td>We consider the distributed source coding prob...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monocular vision SLAM for indoor aerial vehicles</td>\n",
       "      <td>Koray Ã‡elik, Arun K. Somani</td>\n",
       "      <td>2013</td>\n",
       "      <td>IROS'09 Proceedings of the 2009 IEEE/RSJ inter...</td>\n",
       "      <td>This paper presents a novel indoor navigation ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature point extraction from the local freque...</td>\n",
       "      <td>Yang Ling, Wei Jia, Wang Qin, Lu Xiaomin, Cai ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Journal of Electrical and Computer Engineering</td>\n",
       "      <td>We propose a novel technique for detecting rot...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Introduction: The Facebook Phenomenon</td>\n",
       "      <td>Jarice Hanson</td>\n",
       "      <td>2013</td>\n",
       "      <td>Telematics and Informatics</td>\n",
       "      <td>A transcranial Doppler (TCD) is a non-invasive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R.I.P.: Remain in perpetuity. Facebook memoria...</td>\n",
       "      <td>Rebecca Kern, Abbe E. Forman, Gisela Gil-Egui</td>\n",
       "      <td>2013</td>\n",
       "      <td>Telematics and Informatics</td>\n",
       "      <td>Facebook is not only a virtual space to commun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sousveillance: Communities of resistance to th...</td>\n",
       "      <td>Jan Fernback</td>\n",
       "      <td>2013</td>\n",
       "      <td>Telematics and Informatics</td>\n",
       "      <td>Facebook is often invoked in popular discourse...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yearning to be the center of everything, when ...</td>\n",
       "      <td>Barry Vacker, Genevieve Gillespie</td>\n",
       "      <td>2013</td>\n",
       "      <td>Telematics and Informatics</td>\n",
       "      <td>Humans have long sought to map their place in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Communities of participation: A comparison of ...</td>\n",
       "      <td>Paul M. A. Baker, John C. Bricout, Nathan W. M...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Telematics and Informatics</td>\n",
       "      <td>Communication-oriented Internet technologies a...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                Drupal For Designers by Dani Nordin   \n",
       "1  The arithmetical complexity of dimension and r...   \n",
       "2  Low-complexity coding and source-optimized clu...   \n",
       "3   Monocular vision SLAM for indoor aerial vehicles   \n",
       "4  Feature point extraction from the local freque...   \n",
       "5              Introduction: The Facebook Phenomenon   \n",
       "6  R.I.P.: Remain in perpetuity. Facebook memoria...   \n",
       "7  Sousveillance: Communities of resistance to th...   \n",
       "8  Yearning to be the center of everything, when ...   \n",
       "9  Communities of participation: A comparison of ...   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0                              Vasile G. Teodorovici  2013   \n",
       "1        Walid A. Najjar, Raj Yavatkar, Scott Rixner  2013   \n",
       "2                        S. Tucker Taft, Jeff Boleng  2013   \n",
       "3                       Koray Ã‡elik, Arun K. Somani  2013   \n",
       "4  Yang Ling, Wei Jia, Wang Qin, Lu Xiaomin, Cai ...  2013   \n",
       "5                                      Jarice Hanson  2013   \n",
       "6      Rebecca Kern, Abbe E. Forman, Gisela Gil-Egui  2013   \n",
       "7                                       Jan Fernback  2013   \n",
       "8                  Barry Vacker, Genevieve Gillespie  2013   \n",
       "9  Paul M. A. Baker, John C. Bricout, Nathan W. M...  2013   \n",
       "\n",
       "                                               venue  \\\n",
       "0             ACM SIGSOFT Software Engineering Notes   \n",
       "1     ACM Transactions on Computational Logic (TOCL)   \n",
       "2         ACM Transactions on Sensor Networks (TOSN)   \n",
       "3  IROS'09 Proceedings of the 2009 IEEE/RSJ inter...   \n",
       "4     Journal of Electrical and Computer Engineering   \n",
       "5                         Telematics and Informatics   \n",
       "6                         Telematics and Informatics   \n",
       "7                         Telematics and Informatics   \n",
       "8                         Telematics and Informatics   \n",
       "9                         Telematics and Informatics   \n",
       "\n",
       "                                            abstract  citations  \n",
       "0  A semaphore is a non-negative integer variable...          0  \n",
       "1  Constructive dimension and constructive strong...         14  \n",
       "2  We consider the distributed source coding prob...         18  \n",
       "3  This paper presents a novel indoor navigation ...         12  \n",
       "4  We propose a novel technique for detecting rot...         26  \n",
       "5  A transcranial Doppler (TCD) is a non-invasive...          0  \n",
       "6  Facebook is not only a virtual space to commun...          2  \n",
       "7  Facebook is often invoked in popular discourse...          5  \n",
       "8  Humans have long sought to map their place in ...          1  \n",
       "9  Communication-oriented Internet technologies a...         11  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal: figure out what topics received the most citations in a given year\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the data\n",
    "#data_str = open('acm1st10000.txt').read()     # small data\n",
    "#data_str = open('acm.txt',errors=\"ignore\").read()  # BIG DATA  shreyas\n",
    "data_str = open('data/acm.v9/acm.txt',errors=\"ignore\").read()  # BIG DATA  omar\n",
    "\n",
    "data_list = data_str.splitlines()\n",
    "\n",
    "print(data_list[3])\n",
    "print(len(data_list))\n",
    "print(data_list[3][2:])\n",
    "print()\n",
    "\n",
    "# Create the dataframe\n",
    "    # title: (string -- should be bag of words vector)\n",
    "    # authors: (list)\n",
    "    # year: publishing year (int)\n",
    "    # venue: journal the paper was published in (string)\n",
    "    # ind: numeric label/index of this paper (int)\n",
    "    # ref_indces: identification index of the papers that referenced this paper (string)\n",
    "    # abstract: (string -- should be bag of words vector ?)\n",
    "names = ['title', 'authors', 'year', 'venue', 'abstract','citations']\n",
    "\n",
    "\n",
    "#note that we are ignoring ref\n",
    "empty_row = pd.DataFrame(columns=names)\n",
    "df = pd.DataFrame(columns=names)\n",
    "\n",
    "title = \"NULL\"\n",
    "authors = \"NULL\"\n",
    "year = \"NULL\"\n",
    "venue = \"NULL\"\n",
    "index = 0\n",
    "abstract = \"NULL\"\n",
    "citations = 0\n",
    "\n",
    "\n",
    "not1986 = 0\n",
    "\n",
    "dflist = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    if(i%100000 == 0):\n",
    "        print(i)\n",
    "    prefix = data_list[i][0:2]\n",
    "    if prefix == \"#*\": \n",
    "        title = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#@\":\n",
    "        authors = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#t\":\n",
    "        year = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#c\":\n",
    "        venue = data_list[i][2:]\n",
    "        continue\n",
    "    if prefix == \"#!\":\n",
    "        abstract = data_list[i][2:]\n",
    "    if prefix == \"#%\":\n",
    "        citations += 1\n",
    "    if data_list[i] == \"\": #check for the empty string (new article)       \n",
    "        if year == \"2013\":\n",
    "            # print(index,citations) #debug\n",
    "            dflist.append([title, authors, year, venue, abstract,citations])\n",
    "#             df = df.append(empty_row)\n",
    "\n",
    "#             df.at[index,'title'] = title\n",
    "#             df.at[index,'authors'] = authors\n",
    "#             df.at[index,'year'] = year\n",
    "#             df.at[index,'venue'] = venue\n",
    "#             df.at[index,'abstract'] = abstract\n",
    "            title = \"NULL\"\n",
    "            authors = \"NULL\"\n",
    "            year = \"NULL\"\n",
    "            venue = \"NULL\"\n",
    "            abstract = \"NULL\"\n",
    "            \n",
    "            index += 1\n",
    "        citations = 0\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "df = pd.DataFrame.from_records(dflist, columns=names)\n",
    "df.head(10)\n",
    "\n",
    "    \n",
    "# T0-DO:\n",
    "# -----------------------------------------------------------\n",
    "# Force strings in dataframe that we want as ints to be ints\n",
    "# Convert the strings in dataframe to bag of words vectors \n",
    "# Make a dataframe of just 2015 papers\n",
    "\n",
    "# Account for no citations in a dataframe (if citation column is NaN, make it 0)\n",
    "# Account for no abstract (if abstract column is NaN, remove the row completely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df.head(5))\n",
    "#print(newdf)\n",
    "list_2k13_X=df['title'].tolist()\n",
    "list_2k13_Y=df['citations'].tolist()\n",
    "#print(list_2k15_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Omar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110471\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'set_to_add' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f40bd4d31139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#set_to_add=set(['acm','using','based','system','systems','study','computer','model','time','design','adaptive', 'algorithm', 'analysis', 'applications', 'approach', 'computing', 'conference', 'control', 'data', 'detection', 'dynamic', 'efficient', 'fuzzy', 'human', 'information', 'international', 'journal', 'learning', 'method', 'mobile', 'multi', 'network', 'networks', 'optimization', 'performance', 'problem', 'proceedings', 'social', 'software', 'wireless'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstop_words_NLTK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtotal_stopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_words_NLTK\u001b[0m\u001b[1;33m|\u001b[0m\u001b[0mset_to_add\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mBOWvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_stopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBOWvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_2k15_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'set_to_add' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(list_2k13_X))\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#set_to_add=set(['acm','using','based','system','systems','study','computer','model','time','design','adaptive', 'algorithm', 'analysis', 'applications', 'approach', 'computing', 'conference', 'control', 'data', 'detection', 'dynamic', 'efficient', 'fuzzy', 'human', 'information', 'international', 'journal', 'learning', 'method', 'mobile', 'multi', 'network', 'networks', 'optimization', 'performance', 'problem', 'proceedings', 'social', 'software', 'wireless'])\n",
    "stop_words_NLTK = set(stopwords.words('english'))\n",
    "total_stopwords=stop_words_NLTK|set_to_add\n",
    "BOWvectorizer = CountVectorizer(stop_words=total_stopwords, min_df=0.01, max_df=0.8, max_features=30)\n",
    "X = BOWvectorizer.fit_transform(list_2k15_X)\n",
    "print(BOWvectorizer.get_feature_names())\n",
    "TrainingX=X.toarray()[0:len(X.toarray())-1]\n",
    "#TrainingY=\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFIDFVectorizer=TfidfVectorizer(stop_words=stop_words_NLTK, min_df=0.01, max_df=0.9, max_features=30)\n",
    "X = TFIDFVectorizer.fit_transform(list_2k13_X)\n",
    "print(TFIDFVectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
